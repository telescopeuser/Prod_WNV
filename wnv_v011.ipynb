{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# West Nile Virus Mosquito Analysis\n",
    "\n",
    "https://www.kaggle.com/c/predict-west-nile-virus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src='https://kaggle2.blob.core.windows.net/competitions/kaggle/4366/media/moggie2.png' width=8%>\n",
    "\n",
    "By: 顾 瞻 GU Zhan (Sam)\n",
    "\n",
    "June 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Content\n",
    "\n",
    "[1] Prior arts\n",
    "    \n",
    "    \n",
    "[2] Data pre-porcessing\n",
    "    \n",
    "    \n",
    "[3] Modeling\n",
    "    \n",
    "    \n",
    "[4] Evaluation\n",
    "    \n",
    "    \n",
    "[5] What more can be done?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1] Prior arts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/predict-west-nile-virus/leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src='./ref/LB.png' width=100%>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st prize winner: Chaim Linhart (Cardal)\n",
    "\n",
    "https://github.com/Cardal/Kaggle_WestNileVirus\n",
    "\n",
    "**Method:**\n",
    "\n",
    "Heavy probability and curve-fitting techniques were used: using training data to calculated probability/bias based on many data features to infer the impact/coefficient onto wnv probability, i.e. Normal approximation of the distribution of WnvPresent along a year; Trap-bias (the fraction of rows (in that trap) that contain WnvPresent=1 divided by the global ratio of WnvPresent=1); Estimation for number of mosquitoes per row by looking at similar rows (using dist_days, dist_geospace, and species).\n",
    "Some heuristics are used, i.e. outbreaks_daily_factors\n",
    "Leaderboard feedback was used.\n",
    "\n",
    "To calculate a test wnv probability: Adopt a normal distribution as baseline for prediction of all new test cases.\n",
    "Then apply various above mentioned 'coefficients' to adjust the final results. Leaderboard feedback is incorporated as probability multiplier.\n",
    "\n",
    "**Dataset used:** train.csv, leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd prize winner: Lucas Silva & Dmitry Efimov\n",
    "\n",
    "https://github.com/diefimov/west_nile_virus_2015\n",
    "\n",
    "**Method:**\n",
    "Ensemble modelling using: Gradient Boosting Classifier & Regularized Greedy Forest, with two different structured input files.\n",
    "Mosquitoes data and weather data are linked/combined based on 'date' feature, plus Structural features: i.e. TrapCount (number of mosquitos batches for fixed Trap, Date, Species), TrapCountPrevAge, TrapCountPrev.\n",
    "Used Leaderboard feedback: Two types of multipliers have been applied. AUC scores for each year have been obtained from the leaderboard. Using these AUC scores we have constructed the linear regression model to predict relative average PAyear of WnvPresent for each year, the same way we have obtained the relative average PAmonth of WnvPresent by months \n",
    "\n",
    "\n",
    "**Dataset used:** train.csv, weather.csv, leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>[Sam] In this exercise, we are to use all three datasets, train, weather, and spray.</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [2] Data pre-porcessing\n",
    "Explore and visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import print_function, division\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import pandas as pd\n",
    "import operator\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from sklearn import svm\n",
    "from sklearn.utils.validation import check_random_state\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "print(__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input: train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_wnv_raw_train = pd.read_csv('train.csv', encoding='utf-8') \n",
    "df_wnv_raw_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wnv_raw_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_wnv_raw_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src='http://5047-presscdn.pagely.netdna-cdn.com/wp-content/uploads/2015/07/Screen-Shot-2015-07-02-at-2.47.02-PM.png' width=100%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Above figure is obtained from internet.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, col in enumerate(df_wnv_raw_train.columns):\n",
    "    try:\n",
    "        plt.figure(i)\n",
    "        var1 = df_wnv_raw_train[df_wnv_raw_train['WnvPresent'] == 1][col]\n",
    "        var2 = df_wnv_raw_train[df_wnv_raw_train['WnvPresent'] != 1][col]\n",
    "        plt.hist(var2, histtype='stepfilled', bins=50, normed=False, color='blue', alpha=0.5, label='0: Wnv Negative')\n",
    "        plt.hist(var1, histtype='stepfilled', bins=50, normed=False, color='red', alpha=0.5, label='1: Wnv Positive')\n",
    "        plt.title(\"Histogram\")\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel(\"Frequency\")\n",
    "    #     plt.yscale('log')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    except:\n",
    "        plt.figure(i)\n",
    "        sns.countplot(x=col, hue=\"WnvPresent\", data=df_wnv_raw_train, palette=\"Set2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(y=\"Species\", x=\"NumMosquitos\", hue=\"WnvPresent\", data=df_wnv_raw_train, split=True, palette=\"Set2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        col = 'NumMosquitos'\n",
    "        var1 = df_wnv_raw_train[df_wnv_raw_train['WnvPresent'] == 1][col]\n",
    "        var2 = df_wnv_raw_train[df_wnv_raw_train['WnvPresent'] != 1][col]\n",
    "        plt.hist(var2, histtype='stepfilled', bins=50, normed=False, color='blue', alpha=0.5, label='0: Wnv Negative')\n",
    "        plt.hist(var1, histtype='stepfilled', bins=50, normed=False, color='red', alpha=0.5, label='1: Wnv Positive')\n",
    "        plt.title(\"Histogram\")\n",
    "        plt.xlabel(col)\n",
    "        plt.yscale('log')\n",
    "        plt.ylabel(\"Log(Frequency)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>[Sam] Insights:</font> \n",
    "* monthly seasonality\n",
    "* Three mosquito species have WNV\n",
    "* 'Latitude' suggests northern and southern areas with more WNV\n",
    "* WNV is more likey to be found in larger batch of trapped mosquito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy of Mosquito data pre-processing:\n",
    "\n",
    "* Due to 50 mosquitoes cap per batch in data system, group batches on same date, trap, species.\n",
    "* Construct more structural features, to incorporate previous & related rows' info into current row.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input: weather.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_wnv_raw_weather = pd.read_csv('weather.csv', encoding='utf-8') \n",
    "df_wnv_raw_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wnv_raw_weather.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_wnv_raw_weather.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src='https://kaggle2.blob.core.windows.net/forum-message-attachments/76765/2432/closeststation.png' width=100%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Above figure is obtained from internet.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, col in enumerate(df_wnv_raw_weather.columns):\n",
    "        plt.figure(i)\n",
    "        sns.countplot(x=col, hue=\"Station\", data=df_wnv_raw_weather, palette=\"Set2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>[Sam] Insights:</font> \n",
    "* Similar data in Station 1 & 2\n",
    "* Many missing values of Sataion 2\n",
    "* Some features have very few different values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy of Weather data pre-rpocessing:\n",
    "\n",
    "Use station 1 data (more complete) as station 1 and 2 are correlated.\n",
    "\n",
    "\n",
    "Impute missing values inbetween station 1 and 2.\n",
    "\n",
    "Features not to use:\n",
    "* CodeSum \n",
    "* Depth\t\n",
    "* Water1\t\n",
    "* SnowFall\t\n",
    "* PrecipTotal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Input: spray.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_wnv_raw_spray = pd.read_csv('spray.csv', encoding='utf-8') \n",
    "df_wnv_raw_spray.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wnv_raw_spray.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_wnv_raw_spray.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src='https://kaggle2.blob.core.windows.net/competitions/kaggle/4366/media/all_loc_trap.png' width=100%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Above figure is obtained from internet.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_wnv_raw_spray.groupby(['Date']).size().plot(kind='bar')\n",
    "# sns.countplot(y='Date', data=df_wnv_raw_spray, palette=\"Set2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare above few Spray events & WNV mosquito numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_wnv_raw_train.groupby(['Date', 'WnvPresent'])['NumMosquitos'].sum().unstack().plot(kind='bar', stacked=True, color=['b', 'r'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src='./ref/p1.png' width=100%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>[Sam] Insights:</font> \n",
    "* Spray happened in year 2011 and 2013 only.\n",
    "* Decrease of mosquito numbers were seen in Auguest 2011, 2013, suggesting effective spraying.\n",
    "* Spray killed more non-wnv mosquitos then wnv ones.\n",
    "* My internet research: Spray is effective for max 4 months, or undergoing 3 rains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy of Spray data pre-processing:\n",
    "\n",
    "Later analysis suggests trapped mosquito number is linked to wnv, thus in order to reflect spray effects in few years in training data, a multiplier is designed to artificially boost number of trapped mosquitoes, which would not have been killed if no spay applied, in year 2011 & 2013 only.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [3] Modeling Part 1: Pre-modeling in R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To quickly explore data interactively and get feelings of different models' potential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Pre-process data in R and Excel (outside of this notebook)</font>\n",
    "\n",
    "* Use **train.csv** as base: Re-Code Block, Trap, and Species by desc sorting the occurrence of wnv: (number of positive wnv / total number of the feature, aggregated in train.csv).\n",
    "* Aggregate rows based on Date, Trap, Species, to generate new NumMosquitosCombined. This is to handle 50 mosquito cap limit.\n",
    "* De-Duplicate rows based on Date, Trap, and Species\n",
    "* Add new feature NumMosPreTrapSpecies: current row's most recent previous NumMosquitosCombined, which has same Trap, Species as current row.\n",
    "* Add new feature WnvPresentPreTrapSpecies: current row's most recent previous WnvPresent, which has same Trap, Species as current row.\n",
    "* Add new feature NumMosPreBlockSpecies: current row's most recent previous NumMosquitosCombined, which has same Block, Species as current row.\n",
    "* Add new feature WnvPresentPreBlockSpecies: current row's most recent previous WnvPresent, which has same Block, Species as current row.\n",
    "* Add new feature NumMosPreBlockTrap: current row's most recent previous NumMosquitosCombined, which has same Block, Trap as current row.\n",
    "* Add new feature WnvPresentPreBlockTrap: current row's most recent previous WnvPresent, which has same Block, Trap as current row.\n",
    "* Calculate and include all 'Delta': the value difference between above mentioned current & previous features.\n",
    "\n",
    "* Link **weather.csv**: impute missing data from each other. Remove features: CodeSum\tDepth, Water1, SnowFall, PrecipTotal.\n",
    "* Calculate and include all 'Delta': the value difference between above mentioned current & previous weather measurements.\n",
    "\n",
    "* Link **spray.csv**: calculate SprayWeight, which is set to number 2 on the spray date, and then degrade to 1 linearly during next 90 days.\n",
    "* Calculate and include 'artificially boosted' mosquitoes numbers: WeightNumMosquitosCombined, WeightNumMosPreTrapSpecies, WeightNumMosPreBlockSpecies, WeightNumMosPreBlockTrap, \n",
    "* Calculate and include all 'Delta': DeltaWeightNumMosPreTrapSpecies, DeltaWeightNumMosPreBlockSpecies, and DeltaWeightNumMosPreBlockTrap\n",
    "\n",
    "* Conduct k-means (k=10 & 24) clustering in **R** to add new features in to training data: cluster group kmeans8 & kmeans24\n",
    "\n",
    "<img align=\"left\" src='./ref/cluster.png' width=100%>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src='./ref/m_species.png' width=100%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src='./ref/m_block.png' width=100%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src='./ref/m_trap.png' width=100%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src='./ref/NumMosquitos.png' width=100%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src='./ref/cumulative-recode.png' width=100%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src='./ref/boost_importance.png' width=100%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [3] Modeling Part 2: Python scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models to use:\n",
    "\n",
    "* GradientBoostingClassifier\n",
    "* RandomForestClassifier\n",
    "* AdaBoostClassifier\n",
    "* ExtraTreesClassifier\n",
    "* BaggingClassifier\n",
    "* LogisticRegression\n",
    "* SVM kernal RBF\n",
    "* SVM kernal Linear\n",
    "* KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_wnv_raw = pd.read_csv('train_sam2csv.csv', encoding='utf-8') \n",
    "df_wnv_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include relevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_wnv_raw[[\n",
    "# 'IgnConcatTrapSpecies',\n",
    "# 'IgnConcatBlockSpecies',\n",
    "# 'IgnConcatBlockTrap',\n",
    "# 'IgnDate',\n",
    "'Year',\n",
    "'Month',\n",
    "# 'Day',\n",
    "'nthDay',\n",
    "'nthWeek',\n",
    "# 'IgnAddress',\n",
    "# 'IgnSpecies',\n",
    "'Species-ReCode',\n",
    "# 'IgnBlock',\n",
    "'Block-ReCode',\n",
    "# 'IgnStreet',\n",
    "# 'IgnTrap',\n",
    "'Trap-ReCode',\n",
    "# 'IgnAddressNumberAndStreet',\n",
    "'Latitude',\n",
    "'Longitude',\n",
    "'AddressAccuracy',\n",
    "# 'IgnNumMosquitos',\n",
    "\n",
    "# 'WnvPresent',\n",
    "\n",
    "# 'IgnConcatDateTrapSpecies',\n",
    "# 'IgnDeDup',\n",
    "'NumMosquitosCombined',\n",
    "\n",
    "'NumMosPreTrapSpecies',\n",
    "'WnvPresentPreTrapSpecies',\n",
    "'NumMosPreBlockSpecies',\n",
    "'WnvPresentPreBlockSpecies',\n",
    "'NumMosPreBlockTrap',\n",
    "'WnvPresentPreBlockTrap',\n",
    "\n",
    "'Tmax',\n",
    "'Tmin',\n",
    "'Tavg',\n",
    "'Depart',\n",
    "'DewPoint',\n",
    "'WetBulb',\n",
    "'Heat',\n",
    "'Cool',\n",
    "'Sunrise',\n",
    "'Sunset',\n",
    "'StnPressure',\n",
    "'SeaLevel',\n",
    "'ResultSpeed',\n",
    "'ResultDir',\n",
    "'AvgSpeed',\n",
    "    \n",
    "# 'PreTmax',\n",
    "# 'PreTmin',\n",
    "# 'PreTavg',\n",
    "# 'PreDepart',\n",
    "# 'PreDewPoint',\n",
    "# 'PreWetBulb',\n",
    "# 'PreHeat',\n",
    "# 'PreCool',\n",
    "# 'PreSunrise',\n",
    "# 'PreSunset',\n",
    "# 'PreStnPressure',\n",
    "# 'PreSeaLevel',\n",
    "# 'PreResultSpeed',\n",
    "# 'PreResultDir',\n",
    "# 'PreAvgSpeed',\n",
    "    \n",
    "'DeltaTmax',\n",
    "'DeltaTmin',\n",
    "'DeltaTavg',\n",
    "'DeltaDepart',\n",
    "'DeltaDewPoint',\n",
    "'DeltaWetBulb',\n",
    "'DeltaHeat',\n",
    "'DeltaCool',\n",
    "# 'DeltaSunrise',\n",
    "# 'DeltaSunset',\n",
    "'DeltaStnPressure',\n",
    "# 'DeltaSeaLevel',\n",
    "# 'DeltaResultSpeed',\n",
    "# 'DeltaResultDir',\n",
    "# 'DeltaAvgSpeed',\n",
    "    \n",
    "# 'SprayWeight',\n",
    "    \n",
    "'WeightNumMosquitosCombined',\n",
    "\n",
    "# 'WeightNumMosPreTrapSpecies',\n",
    "# 'WeightNumMosPreBlockSpecies',\n",
    "# 'WeightNumMosPreBlockTrap',\n",
    "    \n",
    "'DeltaWeightNumMosPreTrapSpecies',\n",
    "'DeltaWeightNumMosPreBlockSpecies',\n",
    "'DeltaWeightNumMosPreBlockTrap',\n",
    "    \n",
    "'hclust10',\n",
    "'kmeans10',\n",
    "'kmeans24'\n",
    "        ]]\n",
    "\n",
    "X_col = X.columns # get the column list\n",
    "X = StandardScaler().fit_transform(X.as_matrix())\n",
    "y = df_wnv_raw[['WnvPresent']].as_matrix().reshape(len(df_wnv_raw),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [4] Evaluation\n",
    "### K-fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rng = check_random_state(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GB\n",
    "# classifier_GB = GradientBoostingClassifier(n_estimators=500, # score:  (AUC 0.77018), learning_rate=0.005, max_features=5\n",
    "# classifier_GB = GradientBoostingClassifier(n_estimators=500, # score:  (AUC 0.80), learning_rate=0.003, max_features=8\n",
    "classifier_GB = GradientBoostingClassifier(n_estimators=500, # score: 0.94608 (AUC 0.81419), learning_rate=0.001, max_features=8 <<< Best\n",
    "# classifier_GB = GradientBoostingClassifier(n_estimators=500, # score:  (AUC 0.82), learning_rate=0.0005, max_features=8\n",
    "# classifier_GB = GradientBoostingClassifier(n_estimators=500, # score:  (AUC 0.82), learning_rate=0.0001, max_features=8\n",
    "# classifier_GB = GradientBoostingClassifier(n_estimators=1000, # score:  (AUC 0.82), learning_rate=0.0001, max_features=8\n",
    "# classifier_GB = GradientBoostingClassifier(n_estimators=1000, # score:  (AUC 0.82), learning_rate=0.0005, max_features=8\n",
    "# classifier_GB = GradientBoostingClassifier(n_estimators=1000, # score: 0.78735 (AUC 0.76840), learning_rate=0.0005, max_features=8\n",
    "# classifier_GB = GradientBoostingClassifier(n_estimators=200, # score: 0.94608 (AUC 0.78), learning_rate=0.0005, max_depth=4, min_samples_split=30, max_features=5\n",
    "# classifier_GB = GradientBoostingClassifier(n_estimators=500, # score: 0.66030, default learning_rate=0.1\n",
    "# classifier_GB = GradientBoostingClassifier(n_estimators=500, # score: 0.88464 (AUC 0.80), learning_rate=0.0035\n",
    "# classifier_GB = GradientBoostingClassifier(n_estimators=500, # score: 0.85208 (AUC 0.72), learning_rate=0.0035, max_depth=5, min_samples_split=20, max_features=8\n",
    "# classifier_GB = GradientBoostingClassifier(n_estimators=500, # score: 0.90691 (AUC 0.80), learning_rate=0.002\n",
    "# classifier_GB = GradientBoostingClassifier(n_estimators=500, # score: 0.94608, learning_rate=0.0005, max_depth=5, min_samples_split=20\n",
    "# classifier_GB = GradientBoostingClassifier(n_estimators=500, # score: 0.94608, learning_rate=0.0005, max_depth=5, min_samples_split=30\n",
    "# classifier_GB = GradientBoostingClassifier(n_estimators=500, # score: 0.94608, learning_rate=0.0005, max_depth=5, min_samples_split=30, max_features=10\n",
    "# classifier_GB = GradientBoostingClassifier(n_estimators=500, # score: 0.94608, learning_rate=0.0005, max_depth=5, min_samples_split=30, max_features=5\n",
    "# classifier_GB = GradientBoostingClassifier(n_estimators=500, # score: 0.94608, learning_rate=0.0005, max_depth=4, min_samples_split=30, max_features=5\n",
    "# classifier_GB = GradientBoostingClassifier(n_estimators=1000, # score: 0.79112 (AUC 0.70), learning_rate=0.0035, max_depth=5, min_samples_split=30, max_features=10\n",
    "# classifier_GB = GradientBoostingClassifier(n_estimators=1000, # score: 0.94608, learning_rate=0.0005, max_depth=5, min_samples_split=30, max_features=5\n",
    "# classifier_GB = GradientBoostingClassifier(n_estimators=1000, # score: 0.63623, default learning_rate=0.1\n",
    "# classifier_GB = GradientBoostingClassifier(n_estimators=2000, # score: 0.77567, learning_rate=0.0035\n",
    "#                                    loss='deviance',\n",
    "#                                    subsample=1,\n",
    "#                                    max_depth=5,\n",
    "#                                    min_samples_split=20,\n",
    "                                   learning_rate=0.001,\n",
    "                                   max_features=8,\n",
    "                                   random_state=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# AB\n",
    "# classifier_AB = AdaBoostClassifier(n_estimators=100, # score: (AUC 0.81618), learning_rate=0.004\n",
    "# classifier_AB = AdaBoostClassifier(n_estimators=500, # score: 0.94608 (AUC 0.88), learning_rate=0.005\n",
    "# classifier_AB = AdaBoostClassifier(n_estimators=1000, # score:  (AUC 0.87), learning_rate=0.01\n",
    "# classifier_AB = AdaBoostClassifier(n_estimators=1000, # score:  (AUC 0.88), learning_rate=0.0075\n",
    "# classifier_AB = AdaBoostClassifier(n_estimators=1000, # score:  (AUC 0.75), learning_rate=0.0001 <<< pre-matured\n",
    "# classifier_AB = AdaBoostClassifier(n_estimators=1000, # score:  (AUC 0.88), learning_rate=0.005\n",
    "# classifier_AB = AdaBoostClassifier(n_estimators=1000, # score:  (AUC 0.88), learning_rate=0.0025\n",
    "# classifier_AB = AdaBoostClassifier(n_estimators=500, # score: 0.94608 (AUC 0.88), learning_rate=0.0035\n",
    "# classifier_AB = AdaBoostClassifier(n_estimators=100, # score: 0.94608 (AUC 0.77), learning_rate=0.002\n",
    "# classifier_AB = AdaBoostClassifier(n_estimators=500, # score: 0.94608 (AUC 0.85), learning_rate=0.002\n",
    "# classifier_AB = AdaBoostClassifier(n_estimators=500, # score: 0.94608, learning_rate=0.0005\n",
    "# classifier_AB = AdaBoostClassifier(n_estimators=1000, # score: 0.943130082 (AUC 0.88207), learning_rate=0.0035\n",
    "classifier_AB = AdaBoostClassifier(n_estimators=1000, # score: 0.93948 (AUC 0.88358), learning_rate=0.004 <<< Best\n",
    "# classifier_AB = AdaBoostClassifier(n_estimators=1500, # score: 0.92686 (AUC 0.88), learning_rate=0.0035 \n",
    "# classifier_AB = AdaBoostClassifier(n_estimators=2000, # score: 0.63941, default learning_rate=0.1\n",
    "# classifier_AB = AdaBoostClassifier(n_estimators=2000, # score: 0.90117 (AUC 0.87984), learning_rate=0.0035\n",
    "# classifier_AB = AdaBoostClassifier(n_estimators=2000, # score: 0.89056 (AUC 0.88), learning_rate=0.004\n",
    "# classifier_AB = AdaBoostClassifier(n_estimators=2000, # score: 0.83374 (AUC 0.83), learning_rate=0.01\n",
    "                                   learning_rate=0.004,\n",
    "                                   random_state=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RF\n",
    "# classifier_RF = RandomForestClassifier(n_estimators=100, # score:  (AUC 0.66888), max_depth=8, min_samples_split=20,\n",
    "# classifier_RF = RandomForestClassifier(n_estimators=500, # score: 0.90469, max_depth=5, min_samples_split=20,\n",
    "# classifier_RF = RandomForestClassifier(n_estimators=500, # score: 0.90540, max_depth=5, min_samples_split=30,\n",
    "# classifier_RF = RandomForestClassifier(n_estimators=500, # score: 0.93005, max_depth=4, min_samples_split=30,\n",
    "# classifier_RF = RandomForestClassifier(n_estimators=500, # score: 0.93099, max_depth=4, min_samples_split=40,\n",
    "# classifier_RF = RandomForestClassifier(n_estimators=500, # score: 0.93794 (AUC 0.82), max_depth=3, min_samples_split=20,\n",
    "# classifier_RF = RandomForestClassifier(n_estimators=200, # score: 0.93771, max_depth=3, min_samples_split=20,\n",
    "# classifier_RF = RandomForestClassifier(n_estimators=1000, # score: 0.90493, max_depth=5, min_samples_split=30,\n",
    "classifier_RF = RandomForestClassifier(n_estimators=1000, # score: 0.94207 (AUC 0.81870), max_depth=3, min_samples_split=20, <<< Best\n",
    "# classifier_RF = RandomForestClassifier(n_estimators=500, # score: 0.88900, max_depth=5, min_samples_split=30, max_features=10\n",
    "# classifier_RF = RandomForestClassifier(n_estimators=1000, # score: 0.88864, max_depth=5, min_samples_split=30, max_features=10\n",
    "# classifier_RF = RandomForestClassifier(n_estimators=500, # score: 0.77154\n",
    "# classifier_RF = RandomForestClassifier(n_estimators=1000, # score: 0.76469\n",
    "# classifier_RF = RandomForestClassifier(n_estimators=2000, # score: 0.76564\n",
    "#                                     max_features=10,\n",
    "                                    max_depth=3,\n",
    "                                    min_samples_split=20,\n",
    "                                    random_state=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ET\n",
    "# classifier_ET = ExtraTreesClassifier(n_estimators=500, # score: 0.70973\n",
    "# classifier_ET = ExtraTreesClassifier(n_estimators=500, # score: 0.93382 (AUC 0.81), max_depth=5, min_samples_split=30, max_features=10\n",
    "classifier_ET = ExtraTreesClassifier(n_estimators=500, # score: 0.94655 (AUC 0.84364), max_depth=3, min_samples_split=20, max_features=10 <<< Best\n",
    "# classifier_ET = ExtraTreesClassifier(n_estimators=1000, # score: 0.93276, max_depth=5, min_samples_split=30, max_features=10\n",
    "# classifier_ET = ExtraTreesClassifier(n_estimators=1000, # score: 0.94572, max_depth=4, min_samples_split=30, max_features=5\n",
    "# classifier_ET = ExtraTreesClassifier(n_estimators=1000, # score: 0.94608 (AUC 0.82), max_depth=3, min_samples_split=30, max_features=5\n",
    "# classifier_ET = ExtraTreesClassifier(n_estimators=1000, # score:  (AUC 0.84077), max_depth=3, min_samples_split=20, max_features=10\n",
    "# classifier_ET = ExtraTreesClassifier(n_estimators=1000, # score: 0.93241, max_depth=5, min_samples_split=20, max_features=10\n",
    "# classifier_ET = ExtraTreesClassifier(n_estimators=1000, # score: 0.71067\n",
    "# classifier_ET = ExtraTreesClassifier(n_estimators=2000, # score: 0.71149\n",
    "                                    max_depth=3,\n",
    "                                    min_samples_split=20,\n",
    "                                    max_features=10,\n",
    "                                    random_state=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BG\n",
    "# classifier_BG = BaggingClassifier(n_estimators=500, # score: 0.77035, max_features=20\n",
    "# classifier_BG = BaggingClassifier(n_estimators=500, # score: 0.78085 (AUC 0.57037), max_features=10\n",
    "classifier_BG = BaggingClassifier(n_estimators=500, # score: 0.70725 (AUC 0.67845) <<< Best\n",
    "# classifier_BG = BaggingClassifier(n_estimators=200, # score: 0.77707, max_features=10\n",
    "# classifier_BG = BaggingClassifier(n_estimators=1000, # score: 0.78096 (AUC 0.56), max_features=10\n",
    "# classifier_BG = BaggingClassifier(n_estimators=2000, # score:  (AUC 0.51506), max_features=10\n",
    "# classifier_BG = BaggingClassifier(n_estimators=500, # score: 0.76553, max_features=5\n",
    "# classifier_BG = BaggingClassifier(n_estimators=500, # score: 0.70181\n",
    "# classifier_BG = BaggingClassifier(n_estimators=1000, # score: 0.69779\n",
    "# classifier_BG = BaggingClassifier(n_estimators=2000, # score: 0.70004\n",
    "#                                     max_features=10,\n",
    "                                    random_state=rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC in ROC Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n_splits=6\n",
    "\n",
    "def plot_roc(classifier):\n",
    "    # Run classifier with cross-validation and plot ROC curves\n",
    "    cv = StratifiedKFold(n_splits=6)\n",
    "    mean_tpr = 0.0\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "    colors = cycle(['cyan', 'indigo', 'seagreen', 'yellow', 'blue', 'darkorange'])\n",
    "    lw = 2\n",
    "\n",
    "    i = 0\n",
    "    for (train, test), color in zip(cv.split(X, y), colors):\n",
    "        probas_ = classifier.fit(X[train], y[train]).predict_proba(X[test])\n",
    "        # Compute ROC curve and area the curve\n",
    "        fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])\n",
    "        mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "        mean_tpr[0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=lw, color=color,\n",
    "                 label='ROC fold %d (area = %0.5f)' % (i, roc_auc))\n",
    "\n",
    "        i += 1\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=lw, color='k',\n",
    "             label='Luck')\n",
    "\n",
    "    mean_tpr /= cv.get_n_splits(X, y)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    plt.plot(mean_fpr, mean_tpr, color='g', linestyle='--',\n",
    "             label='Mean ROC (area = %0.5f)' % mean_auc, lw=lw)\n",
    "\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_roc(classifier_GB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(classifier_AB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(classifier_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(classifier_ET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(classifier_BG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(classifier_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(classifier_SVCL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(classifier_SVCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Find best 'n_neighbors':\n",
    "import operator\n",
    "from sklearn.cross_validation import train_test_split\n",
    "n_neighbors_best_list = []\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "for n_neighbors in [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31]:\n",
    "    knn = KNeighborsClassifier(n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "    print(n_neighbors, knn.score(X_test, y_test))\n",
    "    n_neighbors_best_list.append(knn.score(X_test, y_test))\n",
    "\n",
    "n_neighbors_best, n_neighbors_value = max(enumerate(n_neighbors_best_list), key=operator.itemgetter(1))\n",
    "# print('\\nBest n_neighbors is: %d \\nwith value : %f' % (n_neighbors_best, n_neighbors_value))\n",
    "print('\\nBest value : %f' % (n_neighbors_value))\n",
    "# plot_roc(KNeighborsClassifier(n_neighbors=n_neighbors_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_roc(KNeighborsClassifier(n_neighbors=11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark of Kaggle public leaderboard progress for top 2 teams\n",
    "Using Kaggle's 30% of actual reserved test data, top 1 & 2 team started from AUC=0.7+, progressing to 0.88+. Leaderboard feedback is expected to have contributed to a few 'jumps'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src='./ref/LB-progress.png' width=100%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src='./ref/LB-hist.png' width=100%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Reflection</font> \n",
    "\n",
    "The best model here, AdaBoostClassifier, used 6-fold cross validation to reach average AUC 0.88, based on test data split from training data. If using 'Kaggle's 30% of actual reserved test data', AUC is expected to drop, nevertheless, I think the initial performance can be reasonably good due to the AUC margin: 0.88 - 0.7 = 0.18."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [5] What more can be done?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Review confusion matrix. (High AUC doesn't translate to high accuracy of WNV identification. It's observed that improved AUC can deteriorate 'Averaged class error/accuracy' for WNV. Unbalanced classes, trade-off considerations.)\n",
    "* Explore better strategy to use spray data, as 'feature importance' indicated: (Weighted) Number of Mosquitoes.\n",
    "* Clustering method is effective, which is a form of building affiliation of relevant rows.\n",
    "* Add heuristics, i.e. use geo-spacial distance of rows/samples to build sample affiliation.\n",
    "* Ensemble several models, i.e. AdaBoost & ExtraTree, to complement CV Folde 2 performance.\n",
    "* Consider to use Leaderboard feedback. (It seems that this WNV result submission is no longer available in Kaggle.)\n",
    "* Quantify the benefit to use this model by comparing against current reactive practice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC\n",
    "<img align=\"left\" src='./ref/ROC_curves.svg.png' width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Feature Importances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def util_feature_importances(classifier):\n",
    "    print(classifier)\n",
    "    dict_importance ={}\n",
    "    for i in range(len(X_col)):\n",
    "        dict_importance[X_col[i]] = classifier.feature_importances_[i]\n",
    "        dict_importance_sort = sorted(dict_importance.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return dict_importance_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util_feature_importances(classifier_GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util_feature_importances(classifier_AB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util_feature_importances(classifier_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util_feature_importances(classifier_ET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_folds = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "cv = cross_val_score(classifier_GB,\n",
    "                            X,\n",
    "                            y,\n",
    "                            cv=StratifiedKFold(n_folds))\n",
    "print('GB score: {0:.5f}'.format(cv.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ada Bossting\n",
    "cv = cross_val_score(classifier_AB,\n",
    "                            X,\n",
    "                            y,\n",
    "                            cv=StratifiedKFold(n_folds))\n",
    "print('AB score: {0:.5f}'.format(cv.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "cv = cross_val_score(classifier_RF,\n",
    "                            X,\n",
    "                            y,\n",
    "                            cv=StratifiedKFold(n_folds))\n",
    "print('RF score: {0:.5f}'.format(cv.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra Tree\n",
    "cv = cross_val_score(classifier_ET,\n",
    "                            X,\n",
    "                            y,\n",
    "                            cv=StratifiedKFold(n_folds))\n",
    "print('ET score: {0:.5f}'.format(cv.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging\n",
    "cv = cross_val_score(classifier_BG,\n",
    "                            X,\n",
    "                            y,\n",
    "                            cv=StratifiedKFold(n_folds))\n",
    "print('BG score: {0:.5f}'.format(cv.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LR\n",
    "classifier_LR = LogisticRegression(random_state=rng) # score: 0.90199 (AUC 0.78022)\n",
    "cv = cross_val_score(classifier_LR,\n",
    "                            X,\n",
    "                            y,\n",
    "                            cv=StratifiedKFold(n_folds))\n",
    "print('LR CV score: {0:.5f}'.format(cv.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC Liner\n",
    "classifier_SVCL = svm.SVC(kernel='linear', probability=True, random_state=rng) # score: 0.89976 (AUC 0.77623)\n",
    "cv = cross_val_score(classifier_SVCL,\n",
    "                            X,\n",
    "                            y,\n",
    "                            cv=StratifiedKFold(n_folds))\n",
    "print('SVC Liner CV score: {0:.5f}'.format(cv.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC RBF\n",
    "classifier_SVCR = svm.SVC(kernel='rbf', probability=True, random_state=rng) # score: 0.80188 (AUC 0.58626)\n",
    "cv = cross_val_score(classifier_SVCR,\n",
    "                            X,\n",
    "                            y,\n",
    "                            cv=StratifiedKFold(n_folds))\n",
    "print('SVC RBF CV score: {0:.5f}'.format(cv.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "classifier_KNN = KNeighborsClassifier(n_neighbors=11) # score: 0.90046 (AUC 0.72792)\n",
    "cv = cross_val_score(classifier_KNN,\n",
    "                            X,\n",
    "                            y,\n",
    "                            cv=StratifiedKFold(n_folds))\n",
    "print('KNN CV score: {0:.5f}'.format(cv.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
